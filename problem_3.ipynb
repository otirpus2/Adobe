{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<title>Image Grouping with Object Detection</title>\n",
    "</head>\n",
    "<body>\n",
    "<h1>Image Grouping with Object Detection</h1>\n",
    "<p>This HTML page provides an overview of the Python script that uses the Ultralytics YOLO library to detect objects in images and group them based on detected entities.</p>\n",
    "\n",
    "<ol>\n",
    "    <li>Import the necessary libraries: The script begins by importing the Ultralytics YOLO class (<code>ultralytics.YOLO</code>), the operating system module (<code>os</code>), the CSV module (<code>csv</code>), and the Image module from the Python Imaging Library (<code>PIL</code>).</li>\n",
    "    <li>Load YOLO Model: The YOLO model is loaded using the pretrained model file named <code>'yolov8n.pt'</code>.</li>\n",
    "    <li>Specify Folder Paths: The paths to the input folder (<code>folder_path</code>) where images are stored and the output folder (<code>output_folder</code>) where grouped images will be saved are defined.</li>\n",
    "    <li>Retrieve File List: The <code>getFolder_Path(folder_path)</code> function is used to retrieve a list of file names from the specified input folder.</li>\n",
    "    <li>Detect and Group Segments: The <code>detect_Segments()</code> function processes each image in the input folder, detects object segments using the YOLO model, counts entities, and groups images based on detected entities.</li>\n",
    "    <li>Count Detected Entities: The <code>count_Entities(results)</code> function counts the detected entities and calculates the total number of detected objects.</li>\n",
    "    <li>Group Images: The <code>group_images(img_name, counts)</code> function creates group folders based on entity IDs and copies images to the appropriate group folder.</li>\n",
    "    <li>Main Module Execution: The script checks if it is being run as the main module, and if so, it calls the <code>detect_Segments()</code> function to initiate the detection and grouping process.</li>\n",
    "</ol>\n",
    "\n",
    "<p>This Python script uses the Ultralytics YOLO library to detect objects in images and group them based on detected entities. Grouped images are saved in separate folders corresponding to the detected entities.</p>\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-image\n",
      "  Obtaining dependency information for scikit-image from https://files.pythonhosted.org/packages/08/c0/8085c5fd2f7f7514a0c5031b666171d5828ac5b3c9cf5d0ecd19688d5407/scikit_image-0.21.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading scikit_image-0.21.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.21.1 in c:\\users\\suprito ghosh\\appdata\\roaming\\python\\python311\\site-packages (from scikit-image) (1.25.1)\n",
      "Requirement already satisfied: scipy>=1.8 in c:\\users\\suprito ghosh\\appdata\\roaming\\python\\python311\\site-packages (from scikit-image) (1.11.1)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\suprito ghosh\\appdata\\roaming\\python\\python311\\site-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in c:\\users\\suprito ghosh\\appdata\\roaming\\python\\python311\\site-packages (from scikit-image) (10.0.0)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\suprito ghosh\\appdata\\roaming\\python\\python311\\site-packages (from scikit-image) (2.31.1)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Obtaining dependency information for tifffile>=2022.8.12 from https://files.pythonhosted.org/packages/74/68/19989a1009f68ed777ea5d2624c2996bab0890a31ce7d4b2a7ae4e1c0cfe/tifffile-2023.8.12-py3-none-any.whl.metadata\n",
      "  Downloading tifffile-2023.8.12-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting PyWavelets>=1.1.1 (from scikit-image)\n",
      "  Downloading PyWavelets-1.4.1-cp311-cp311-win_amd64.whl (4.2 MB)\n",
      "     ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.1/4.2 MB 1.1 MB/s eta 0:00:04\n",
      "     - -------------------------------------- 0.2/4.2 MB 2.0 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 0.4/4.2 MB 3.4 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 0.8/4.2 MB 4.2 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 1.2/4.2 MB 5.5 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 2.0/4.2 MB 7.4 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 2.1/4.2 MB 7.3 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 2.8/4.2 MB 7.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  4.2/4.2 MB 10.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.2/4.2 MB 9.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\suprito ghosh\\appdata\\roaming\\python\\python311\\site-packages (from scikit-image) (23.1)\n",
      "Collecting lazy_loader>=0.2 (from scikit-image)\n",
      "  Obtaining dependency information for lazy_loader>=0.2 from https://files.pythonhosted.org/packages/a1/c3/65b3814e155836acacf720e5be3b5757130346670ac454fee29d3eda1381/lazy_loader-0.3-py3-none-any.whl.metadata\n",
      "  Downloading lazy_loader-0.3-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading scikit_image-0.21.0-cp311-cp311-win_amd64.whl (22.8 MB)\n",
      "   ---------------------------------------- 0.0/22.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/22.8 MB 32.3 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 1.6/22.8 MB 20.4 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 2.4/22.8 MB 19.3 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 2.4/22.8 MB 19.3 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 4.1/22.8 MB 18.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 4.7/22.8 MB 17.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 5.3/22.8 MB 16.9 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 5.8/22.8 MB 16.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 6.3/22.8 MB 15.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 7.1/22.8 MB 15.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 7.5/22.8 MB 15.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 8.1/22.8 MB 14.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 8.6/22.8 MB 14.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 9.1/22.8 MB 14.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 9.6/22.8 MB 13.9 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 9.7/22.8 MB 13.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 10.4/22.8 MB 13.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 10.8/22.8 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 11.2/22.8 MB 12.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 11.5/22.8 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 11.9/22.8 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 12.1/22.8 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 12.6/22.8 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 12.8/22.8 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 13.0/22.8 MB 10.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 13.3/22.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 13.5/22.8 MB 9.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 13.6/22.8 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 13.8/22.8 MB 8.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 14.0/22.8 MB 8.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 14.2/22.8 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 14.4/22.8 MB 8.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 14.6/22.8 MB 7.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 14.8/22.8 MB 7.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 15.0/22.8 MB 7.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 15.1/22.8 MB 7.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 15.3/22.8 MB 7.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 15.5/22.8 MB 7.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 15.7/22.8 MB 7.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 15.9/22.8 MB 6.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 16.1/22.8 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 16.3/22.8 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 16.5/22.8 MB 6.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 16.7/22.8 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 16.8/22.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 17.1/22.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 17.3/22.8 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 17.5/22.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 17.7/22.8 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 17.9/22.8 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 18.0/22.8 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 18.3/22.8 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 18.5/22.8 MB 5.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 18.7/22.8 MB 5.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 18.9/22.8 MB 5.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 19.1/22.8 MB 5.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 19.3/22.8 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 19.5/22.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 19.7/22.8 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 19.7/22.8 MB 4.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 20.1/22.8 MB 4.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 20.2/22.8 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 20.4/22.8 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 20.5/22.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 20.6/22.8 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 20.8/22.8 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 20.9/22.8 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 21.1/22.8 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 21.2/22.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 21.4/22.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 21.5/22.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 21.6/22.8 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 21.8/22.8 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 21.9/22.8 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 22.0/22.8 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 22.2/22.8 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  22.3/22.8 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  22.4/22.8 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  22.5/22.8 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  22.6/22.8 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  22.7/22.8 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  22.8/22.8 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  22.8/22.8 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 22.8/22.8 MB 3.6 MB/s eta 0:00:00\n",
      "Downloading lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Downloading tifffile-2023.8.12-py3-none-any.whl (220 kB)\n",
      "   ---------------------------------------- 0.0/221.0 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 30.7/221.0 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 204.8/221.0 kB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 221.0/221.0 kB 2.3 MB/s eta 0:00:00\n",
      "Installing collected packages: tifffile, PyWavelets, lazy_loader, scikit-image\n",
      "Successfully installed PyWavelets-1.4.1 lazy_loader-0.3 scikit-image-0.21.0 tifffile-2023.8.12\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\1.jpg: 384x640 4 persons, 1 couch, 654.2ms\n",
      "Speed: 14.6ms preprocess, 654.2ms inference, 30.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for 1.jpg\n",
      "Data saved to ./runs/detect/predict/1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\2.jpg: 448x640 3 persons, 1 bed, 452.0ms\n",
      "Speed: 10.5ms preprocess, 452.0ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for 2.jpg\n",
      "Data saved to ./runs/detect/predict/2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\3.jpg: 448x640 3 persons, 702.3ms\n",
      "Speed: 7.6ms preprocess, 702.3ms inference, 9.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for 3.jpg\n",
      "Data saved to ./runs/detect/predict/3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_112814949.jpeg: 448x640 1 spoon, 1 bowl, 1 sandwich, 475.8ms\n",
      "Speed: 8.0ms preprocess, 475.8ms inference, 3.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for AdobeStock_112814949.jpeg\n",
      "Data saved to ./runs/detect/predict/AdobeStock_112814949.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_119085612.jpeg: 480x640 1 cup, 1 toothbrush, 267.7ms\n",
      "Speed: 6.6ms preprocess, 267.7ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for AdobeStock_119085612.jpeg\n",
      "Data saved to ./runs/detect/predict/AdobeStock_119085612.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_189740072.jpeg: 448x640 1 person, 199.1ms\n",
      "Speed: 4.5ms preprocess, 199.1ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for AdobeStock_189740072.jpeg\n",
      "Data saved to ./runs/detect/predict/AdobeStock_189740072.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_254640691.jpeg: 448x640 1 spoon, 4 bowls, 3 oranges, 1 dining table, 289.5ms\n",
      "Speed: 10.1ms preprocess, 289.5ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for AdobeStock_254640691.jpeg\n",
      "Data saved to ./runs/detect/predict/AdobeStock_254640691.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_255497590.jpeg: 352x640 1 bowl, 186.7ms\n",
      "Speed: 6.0ms preprocess, 186.7ms inference, 7.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for AdobeStock_255497590.jpeg\n",
      "Data saved to ./runs/detect/predict/AdobeStock_255497590.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_257024669.jpeg: 448x640 1 suitcase, 318.2ms\n",
      "Speed: 5.6ms preprocess, 318.2ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for AdobeStock_257024669.jpeg\n",
      "Data saved to ./runs/detect/predict/AdobeStock_257024669.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_286178925.jpeg: 448x640 5 bowls, 6 donuts, 1 cake, 1 dining table, 365.3ms\n",
      "Speed: 7.2ms preprocess, 365.3ms inference, 7.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for AdobeStock_286178925.jpeg\n",
      "Data saved to ./runs/detect/predict/AdobeStock_286178925.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_297274410.jpeg: 448x640 2 persons, 3 bowls, 1 dining table, 332.9ms\n",
      "Speed: 9.1ms preprocess, 332.9ms inference, 3.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for AdobeStock_297274410.jpeg\n",
      "Data saved to ./runs/detect/predict/AdobeStock_297274410.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_315333860.jpeg: 448x640 3 persons, 1 wine glass, 4 cups, 1 spoon, 1 bowl, 4 pizzas, 1 dining table, 262.6ms\n",
      "Speed: 5.5ms preprocess, 262.6ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for AdobeStock_315333860.jpeg\n",
      "Data saved to ./runs/detect/predict/AdobeStock_315333860.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_321810820.jpeg: 384x640 5 persons, 1 skateboard, 216.7ms\n",
      "Speed: 10.2ms preprocess, 216.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for AdobeStock_321810820.jpeg\n",
      "Data saved to ./runs/detect/predict/AdobeStock_321810820.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_323628715.jpeg: 448x640 7 persons, 2 cups, 1 bowl, 4 pizzas, 1 dining table, 302.2ms\n",
      "Speed: 8.1ms preprocess, 302.2ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for AdobeStock_323628715.jpeg\n",
      "Data saved to ./runs/detect/predict/AdobeStock_323628715.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_349162891.jpeg: 608x640 1 sandwich, 311.4ms\n",
      "Speed: 9.4ms preprocess, 311.4ms inference, 4.5ms postprocess per image at shape (1, 3, 608, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for AdobeStock_349162891.jpeg\n",
      "Data saved to ./runs/detect/predict/AdobeStock_349162891.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_425653713.jpeg: 448x640 1 handbag, 1 bowl, 1 potted plant, 1 bed, 1 laptop, 1 keyboard, 268.0ms\n",
      "Speed: 3.0ms preprocess, 268.0ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for AdobeStock_425653713.jpeg\n",
      "Data saved to ./runs/detect/predict/AdobeStock_425653713.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_57849082.jpeg: 448x640 1 person, 2 pizzas, 1 dining table, 297.5ms\n",
      "Speed: 4.0ms preprocess, 297.5ms inference, 3.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for AdobeStock_57849082.jpeg\n",
      "Data saved to ./runs/detect/predict/AdobeStock_57849082.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_58143201.jpeg: 480x640 (no detections), 275.0ms\n",
      "Speed: 6.6ms preprocess, 275.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for AdobeStock_58143201.jpeg\n",
      "Data saved to ./runs/detect/predict/AdobeStock_58143201.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_584637362.jpeg: 448x640 2 airplanes, 3 suitcases, 176.7ms\n",
      "Speed: 4.1ms preprocess, 176.7ms inference, 3.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for AdobeStock_584637362.jpeg\n",
      "Data saved to ./runs/detect/predict/AdobeStock_584637362.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_594853635.jpeg: 224x640 8 sandwichs, 123.0ms\n",
      "Speed: 2.0ms preprocess, 123.0ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for AdobeStock_594853635.jpeg\n",
      "Data saved to ./runs/detect/predict/AdobeStock_594853635.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_608957878.jpeg: 448x640 2 persons, 2 toothbrushs, 348.6ms\n",
      "Speed: 7.6ms preprocess, 348.6ms inference, 2.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for AdobeStock_608957878.jpeg\n",
      "Data saved to ./runs/detect/predict/AdobeStock_608957878.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_618914535.jpeg: 480x640 2 sandwichs, 241.2ms\n",
      "Speed: 6.6ms preprocess, 241.2ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for AdobeStock_618914535.jpeg\n",
      "Data saved to ./runs/detect/predict/AdobeStock_618914535.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_92669497.jpeg: 448x640 7 persons, 1 suitcase, 223.9ms\n",
      "Speed: 5.1ms preprocess, 223.9ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for AdobeStock_92669497.jpeg\n",
      "Data saved to ./runs/detect/predict/AdobeStock_92669497.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_96284524.jpeg: 448x640 12 donuts, 233.9ms\n",
      "Speed: 9.3ms preprocess, 233.9ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for AdobeStock_96284524.jpeg\n",
      "Data saved to ./runs/detect/predict/AdobeStock_96284524.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\DL.jpeg: 384x640 1 bottle, 207.0ms\n",
      "Speed: 5.0ms preprocess, 207.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for DL.jpeg\n",
      "Data saved to ./runs/detect/predict/DL.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\maxresdefault.jpeg: 384x640 3 persons, 197.3ms\n",
      "Speed: 5.1ms preprocess, 197.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for maxresdefault.jpeg\n",
      "Data saved to ./runs/detect/predict/maxresdefault.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\Mist.jpeg: 448x640 1 tie, 246.2ms\n",
      "Speed: 5.3ms preprocess, 246.2ms inference, 2.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images grouped for Mist.jpeg\n",
      "Data saved to ./runs/detect/predict/Mist.csv\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO('yolov8n.pt')  # Using yolov8n pretrained model\n",
    "folder_path = './All_Images'  # Path to folder where images are stored\n",
    "output_folder = './output/problem3/'  # Path to folder where grouped images will be saved\n",
    "\n",
    "def getFolder_Path(folder_path):\n",
    "    # Getting the path to all files in a list\n",
    "    file_list = []\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file_name in files:\n",
    "            file_list.append(file_name)\n",
    "    return file_list\n",
    "\n",
    "def detect_Segments():\n",
    "    # Using YOLO to detect objects in every image\n",
    "    files_in_folder = getFolder_Path(folder_path)\n",
    "    for i in files_in_folder:\n",
    "        path = f'./All_Images/{i}'\n",
    "        results = model.predict(path, save=True)\n",
    "        counts, total_objects = count_Entities(results)\n",
    "        group_images(i, counts)\n",
    "        write_to_CSV(i, counts, total_objects)\n",
    "\n",
    "def count_Entities(results):\n",
    "    # Counting entities detected in the results\n",
    "    counts = {}\n",
    "    total_objects = 0\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes.cpu().numpy()\n",
    "        total_objects += len(boxes)\n",
    "        for box in boxes:\n",
    "            cls = int(box.cls[0])\n",
    "            if cls not in counts:\n",
    "                counts[cls] = 1\n",
    "            else:\n",
    "                counts[cls] += 1\n",
    "\n",
    "    return counts, total_objects\n",
    "\n",
    "def write_to_CSV(img_name, counts, total_objects):\n",
    "    # Writing the data to a CSV file\n",
    "    name = img_name.split('.')[0]\n",
    "    csv_path = f\"./runs/detect/predict/{name}.csv\"\n",
    "\n",
    "    with open(csv_path, mode='w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(['Entity', 'Count'])\n",
    "        for key in counts:\n",
    "            writer.writerow([model.names[key], counts[key]])\n",
    "        writer.writerow(['Total Objects', total_objects])\n",
    "\n",
    "    print(f\"Data saved to {csv_path}\")\n",
    "\n",
    "def calculate_image_similarity(image1_path, image2_path):\n",
    "    # Calculate the structural similarity index between two images\n",
    "    image1 = Image.open(image1_path).convert(\"L\")\n",
    "    image2 = Image.open(image2_path).convert(\"L\")\n",
    "    similarity = ssim(np.array(image1), np.array(image2))\n",
    "    return similarity\n",
    "\n",
    "def group_images(img_name, counts):\n",
    "    # Creating folders based on detected entities and moving images\n",
    "    for entity_id in counts:\n",
    "        entity_name = model.names[entity_id]\n",
    "        group_folder = f\"{output_folder}/Folder-grp{entity_id}_{entity_name}\"\n",
    "        if not os.path.exists(group_folder):\n",
    "            os.makedirs(group_folder)\n",
    "\n",
    "        src_path = f\"./All_Images/{img_name}\"\n",
    "        dst_path = f\"{group_folder}/{img_name}\"\n",
    "        shutil.copy(src_path, dst_path)\n",
    "\n",
    "    print(f\"Images grouped for {img_name}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    detect_Segments()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
